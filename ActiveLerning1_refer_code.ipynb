{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/9-coding/ComputerVision_TeamProject/blob/main/ActiveLerning1_refer_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23fzKM-78jta",
        "outputId": "a52efddf-e8f4-4561-e6bf-f87768ee8ee0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# 각자 환경에서 이 부분만 변경하여 사용하면 됩니다.\n",
        "os.chdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50')\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPJyNlOGHEeZ",
        "outputId": "afd36170-9894-4425-a98a-dfc8c2af234e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/CUB_200_2011_repackage_class50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arC4zHzyvspS",
        "outputId": "af158703-b6c7-4bef-b7df-11c5875dc2ca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.34.0-py2.py3-none-any.whl (243 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.9/243.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=7cc5cdcb500ad2cf05a305f664bbeccf49a138f502e0ffb8dab897976261b362\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.40 docker-pycreds-0.4.0 gitdb-4.0.11 pathtools-0.1.2 sentry-sdk-1.34.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.15.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login f9fc6c65de4904021a59f4c8c60b90961f6ec1fb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwkWrwD3vswF",
        "outputId": "ee4307f4-6b59-4fad-98eb-7081428328c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9PKQJdLs4DbQ",
        "outputId": "3b70b158-79c1-411e-93a3-bcb159f6574f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set as 42\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:0554elrr) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">distinctive-cherry-30</strong> at: <a href='https://wandb.ai/computervisionactivelearning/activelearning1_doyeon/runs/0554elrr' target=\"_blank\">https://wandb.ai/computervisionactivelearning/activelearning1_doyeon/runs/0554elrr</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231104_051810-0554elrr/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:0554elrr). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/wandb/run-20231104_051915-8qssmv7b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/computervisionactivelearning/activelearning1_doyeon/runs/8qssmv7b' target=\"_blank\">sweet-sunset-31</a></strong> to <a href='https://wandb.ai/computervisionactivelearning/activelearning1_doyeon' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/computervisionactivelearning/activelearning1_doyeon' target=\"_blank\">https://wandb.ai/computervisionactivelearning/activelearning1_doyeon</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/computervisionactivelearning/activelearning1_doyeon/runs/8qssmv7b' target=\"_blank\">https://wandb.ai/computervisionactivelearning/activelearning1_doyeon/runs/8qssmv7b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Num of each dataset: 2360 296 298\n",
            "Loaded dataloader\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a learning model and optimizer\n",
            "Train Epoch 0 [0/74]\tLoss: 4.035903\n",
            "Train Epoch 0 [10/74]\tLoss: 4.027269\n",
            "Train Epoch 0 [20/74]\tLoss: 3.009481\n",
            "Train Epoch 0 [30/74]\tLoss: 2.154206\n",
            "Train Epoch 0 [40/74]\tLoss: 1.712796\n",
            "Train Epoch 0 [50/74]\tLoss: 1.448546\n",
            "Train Epoch 0 [60/74]\tLoss: 1.374756\n",
            "Train Epoch 0 [70/74]\tLoss: 1.353383\n",
            "[0] Validation Loss: 1.4281, Accuracy: 62.8378%\n",
            "Train Epoch 1 [0/74]\tLoss: 1.008552\n",
            "Train Epoch 1 [10/74]\tLoss: 0.906048\n",
            "Train Epoch 1 [20/74]\tLoss: 0.510415\n",
            "Train Epoch 1 [30/74]\tLoss: 0.738527\n",
            "Train Epoch 1 [40/74]\tLoss: 0.648519\n",
            "Train Epoch 1 [50/74]\tLoss: 0.449418\n",
            "Train Epoch 1 [60/74]\tLoss: 0.512316\n",
            "Train Epoch 1 [70/74]\tLoss: 0.310407\n",
            "[1] Validation Loss: 0.9128, Accuracy: 76.3514%\n",
            "Train Epoch 2 [0/74]\tLoss: 0.230892\n",
            "Train Epoch 2 [10/74]\tLoss: 0.127092\n",
            "Train Epoch 2 [20/74]\tLoss: 0.162602\n",
            "Train Epoch 2 [30/74]\tLoss: 0.097363\n",
            "Train Epoch 2 [40/74]\tLoss: 0.185083\n",
            "Train Epoch 2 [50/74]\tLoss: 0.120765\n",
            "Train Epoch 2 [60/74]\tLoss: 0.153913\n",
            "Train Epoch 2 [70/74]\tLoss: 0.153792\n",
            "[2] Validation Loss: 0.5761, Accuracy: 84.1216%\n",
            "Train Epoch 3 [0/74]\tLoss: 0.071924\n",
            "Train Epoch 3 [10/74]\tLoss: 0.057016\n",
            "Train Epoch 3 [20/74]\tLoss: 0.090090\n",
            "Train Epoch 3 [30/74]\tLoss: 0.053375\n",
            "Train Epoch 3 [40/74]\tLoss: 0.050834\n",
            "Train Epoch 3 [50/74]\tLoss: 0.069808\n",
            "Train Epoch 3 [60/74]\tLoss: 0.044999\n",
            "Train Epoch 3 [70/74]\tLoss: 0.045831\n",
            "[3] Validation Loss: 0.4149, Accuracy: 89.1892%\n",
            "Train Epoch 4 [0/74]\tLoss: 0.041502\n",
            "Train Epoch 4 [10/74]\tLoss: 0.029526\n",
            "Train Epoch 4 [20/74]\tLoss: 0.016775\n",
            "Train Epoch 4 [30/74]\tLoss: 0.030444\n",
            "Train Epoch 4 [40/74]\tLoss: 0.033539\n",
            "Train Epoch 4 [50/74]\tLoss: 0.030136\n",
            "Train Epoch 4 [60/74]\tLoss: 0.025530\n",
            "Train Epoch 4 [70/74]\tLoss: 0.031248\n",
            "[4] Validation Loss: 0.3917, Accuracy: 89.8649%\n",
            "Train Epoch 5 [0/74]\tLoss: 0.019961\n",
            "Train Epoch 5 [10/74]\tLoss: 0.025484\n",
            "Train Epoch 5 [20/74]\tLoss: 0.018079\n",
            "Train Epoch 5 [30/74]\tLoss: 0.015638\n",
            "Train Epoch 5 [40/74]\tLoss: 0.019020\n",
            "Train Epoch 5 [50/74]\tLoss: 0.015088\n",
            "Train Epoch 5 [60/74]\tLoss: 0.017716\n",
            "Train Epoch 5 [70/74]\tLoss: 0.017654\n",
            "[5] Validation Loss: 0.3611, Accuracy: 89.8649%\n",
            "Train Epoch 6 [0/74]\tLoss: 0.025040\n",
            "Train Epoch 6 [10/74]\tLoss: 0.015131\n",
            "Train Epoch 6 [20/74]\tLoss: 0.016774\n",
            "Train Epoch 6 [30/74]\tLoss: 0.010757\n",
            "Train Epoch 6 [40/74]\tLoss: 0.011296\n",
            "Train Epoch 6 [50/74]\tLoss: 0.012176\n",
            "Train Epoch 6 [60/74]\tLoss: 0.010454\n",
            "Train Epoch 6 [70/74]\tLoss: 0.014490\n",
            "[6] Validation Loss: 0.3543, Accuracy: 90.8784%\n",
            "Train Epoch 7 [0/74]\tLoss: 0.009944\n",
            "Train Epoch 7 [10/74]\tLoss: 0.010774\n",
            "Train Epoch 7 [20/74]\tLoss: 0.010607\n",
            "Train Epoch 7 [30/74]\tLoss: 0.018106\n",
            "Train Epoch 7 [40/74]\tLoss: 0.019577\n",
            "Train Epoch 7 [50/74]\tLoss: 0.011098\n",
            "Train Epoch 7 [60/74]\tLoss: 0.013772\n",
            "Train Epoch 7 [70/74]\tLoss: 0.012607\n",
            "[7] Validation Loss: 0.3482, Accuracy: 91.8919%\n",
            "Train Epoch 8 [0/74]\tLoss: 0.009387\n",
            "Train Epoch 8 [10/74]\tLoss: 0.011807\n",
            "Train Epoch 8 [20/74]\tLoss: 0.011871\n",
            "Train Epoch 8 [30/74]\tLoss: 0.011574\n",
            "Train Epoch 8 [40/74]\tLoss: 0.008109\n",
            "Train Epoch 8 [50/74]\tLoss: 0.014562\n",
            "Train Epoch 8 [60/74]\tLoss: 0.006495\n",
            "Train Epoch 8 [70/74]\tLoss: 0.007078\n",
            "[8] Validation Loss: 0.3469, Accuracy: 90.5405%\n",
            "Train Epoch 9 [0/74]\tLoss: 0.009717\n",
            "Train Epoch 9 [10/74]\tLoss: 0.010098\n",
            "Train Epoch 9 [20/74]\tLoss: 0.010532\n",
            "Train Epoch 9 [30/74]\tLoss: 0.006629\n",
            "Train Epoch 9 [40/74]\tLoss: 0.008040\n",
            "Train Epoch 9 [50/74]\tLoss: 0.005771\n",
            "Train Epoch 9 [60/74]\tLoss: 0.013580\n",
            "Train Epoch 9 [70/74]\tLoss: 0.006352\n",
            "[9] Validation Loss: 0.3406, Accuracy: 91.2162%\n",
            "Train Epoch 10 [0/74]\tLoss: 0.005493\n",
            "Train Epoch 10 [10/74]\tLoss: 0.006627\n",
            "Train Epoch 10 [20/74]\tLoss: 0.009460\n",
            "Train Epoch 10 [30/74]\tLoss: 0.006099\n",
            "Train Epoch 10 [40/74]\tLoss: 0.011735\n",
            "Train Epoch 10 [50/74]\tLoss: 0.006206\n",
            "Train Epoch 10 [60/74]\tLoss: 0.005234\n",
            "Train Epoch 10 [70/74]\tLoss: 0.005634\n",
            "[10] Validation Loss: 0.3392, Accuracy: 91.2162%\n",
            "Train Epoch 11 [0/74]\tLoss: 0.009095\n",
            "Train Epoch 11 [10/74]\tLoss: 0.004752\n",
            "Train Epoch 11 [20/74]\tLoss: 0.008422\n",
            "Train Epoch 11 [30/74]\tLoss: 0.006072\n",
            "Train Epoch 11 [40/74]\tLoss: 0.005718\n",
            "Train Epoch 11 [50/74]\tLoss: 0.005265\n",
            "Train Epoch 11 [60/74]\tLoss: 0.003236\n",
            "Train Epoch 11 [70/74]\tLoss: 0.004685\n",
            "[11] Validation Loss: 0.3320, Accuracy: 91.2162%\n",
            "Train Epoch 12 [0/74]\tLoss: 0.004064\n",
            "Train Epoch 12 [10/74]\tLoss: 0.005740\n",
            "Train Epoch 12 [20/74]\tLoss: 0.005769\n",
            "Train Epoch 12 [30/74]\tLoss: 0.010165\n",
            "Train Epoch 12 [40/74]\tLoss: 0.008716\n",
            "Train Epoch 12 [50/74]\tLoss: 0.006969\n",
            "Train Epoch 12 [60/74]\tLoss: 0.006060\n",
            "Train Epoch 12 [70/74]\tLoss: 0.005933\n",
            "[12] Validation Loss: 0.3564, Accuracy: 91.2162%\n",
            "Train Epoch 13 [0/74]\tLoss: 0.005121\n",
            "Train Epoch 13 [10/74]\tLoss: 0.010067\n",
            "Train Epoch 13 [20/74]\tLoss: 0.006768\n",
            "Train Epoch 13 [30/74]\tLoss: 0.004893\n",
            "Train Epoch 13 [40/74]\tLoss: 0.009250\n",
            "Train Epoch 13 [50/74]\tLoss: 0.003769\n",
            "Train Epoch 13 [60/74]\tLoss: 0.005631\n",
            "Train Epoch 13 [70/74]\tLoss: 0.003346\n",
            "[13] Validation Loss: 0.3332, Accuracy: 91.5541%\n",
            "Train Epoch 14 [0/74]\tLoss: 0.004896\n",
            "Train Epoch 14 [10/74]\tLoss: 0.002954\n",
            "Train Epoch 14 [20/74]\tLoss: 0.004531\n",
            "Train Epoch 14 [30/74]\tLoss: 0.007956\n",
            "Train Epoch 14 [40/74]\tLoss: 0.004731\n",
            "Train Epoch 14 [50/74]\tLoss: 0.005429\n",
            "Train Epoch 14 [60/74]\tLoss: 0.004548\n",
            "Train Epoch 14 [70/74]\tLoss: 0.003820\n",
            "[14] Validation Loss: 0.3339, Accuracy: 91.2162%\n",
            "Train Epoch 15 [0/74]\tLoss: 0.005415\n",
            "Train Epoch 15 [10/74]\tLoss: 0.005350\n",
            "Train Epoch 15 [20/74]\tLoss: 0.004773\n",
            "Train Epoch 15 [30/74]\tLoss: 0.006568\n",
            "Train Epoch 15 [40/74]\tLoss: 0.005704\n",
            "Train Epoch 15 [50/74]\tLoss: 0.004078\n",
            "Train Epoch 15 [60/74]\tLoss: 0.004026\n",
            "Train Epoch 15 [70/74]\tLoss: 0.005186\n",
            "[15] Validation Loss: 0.3268, Accuracy: 91.5541%\n",
            "Train Epoch 16 [0/74]\tLoss: 0.003262\n",
            "Train Epoch 16 [10/74]\tLoss: 0.002737\n",
            "Train Epoch 16 [20/74]\tLoss: 0.004534\n",
            "Train Epoch 16 [30/74]\tLoss: 0.002722\n",
            "Train Epoch 16 [40/74]\tLoss: 0.006405\n",
            "Train Epoch 16 [50/74]\tLoss: 0.003324\n",
            "Train Epoch 16 [60/74]\tLoss: 0.004858\n",
            "Train Epoch 16 [70/74]\tLoss: 0.003405\n",
            "[16] Validation Loss: 0.3307, Accuracy: 90.5405%\n",
            "Train Epoch 17 [0/74]\tLoss: 0.006196\n",
            "Train Epoch 17 [10/74]\tLoss: 0.004682\n",
            "Train Epoch 17 [20/74]\tLoss: 0.004322\n",
            "Train Epoch 17 [30/74]\tLoss: 0.003898\n",
            "Train Epoch 17 [40/74]\tLoss: 0.003966\n",
            "Train Epoch 17 [50/74]\tLoss: 0.003298\n",
            "Train Epoch 17 [60/74]\tLoss: 0.006170\n",
            "Train Epoch 17 [70/74]\tLoss: 0.003008\n",
            "[17] Validation Loss: 0.3273, Accuracy: 90.8784%\n",
            "Train Epoch 18 [0/74]\tLoss: 0.003227\n",
            "Train Epoch 18 [10/74]\tLoss: 0.004604\n",
            "Train Epoch 18 [20/74]\tLoss: 0.004262\n",
            "Train Epoch 18 [30/74]\tLoss: 0.003667\n",
            "Train Epoch 18 [40/74]\tLoss: 0.005111\n",
            "Train Epoch 18 [50/74]\tLoss: 0.002856\n",
            "Train Epoch 18 [60/74]\tLoss: 0.003869\n",
            "Train Epoch 18 [70/74]\tLoss: 0.002432\n",
            "[18] Validation Loss: 0.3276, Accuracy: 91.5541%\n",
            "Train Epoch 19 [0/74]\tLoss: 0.002200\n",
            "Train Epoch 19 [10/74]\tLoss: 0.003415\n",
            "Train Epoch 19 [20/74]\tLoss: 0.003952\n",
            "Train Epoch 19 [30/74]\tLoss: 0.004576\n",
            "Train Epoch 19 [40/74]\tLoss: 0.002385\n",
            "Train Epoch 19 [50/74]\tLoss: 0.003685\n",
            "Train Epoch 19 [60/74]\tLoss: 0.002683\n",
            "Train Epoch 19 [70/74]\tLoss: 0.003402\n",
            "[19] Validation Loss: 0.3230, Accuracy: 91.2162%\n",
            "Train Epoch 20 [0/74]\tLoss: 0.003211\n",
            "Train Epoch 20 [10/74]\tLoss: 0.003116\n",
            "Train Epoch 20 [20/74]\tLoss: 0.003288\n",
            "Train Epoch 20 [30/74]\tLoss: 0.002850\n",
            "Train Epoch 20 [40/74]\tLoss: 0.004027\n",
            "Train Epoch 20 [50/74]\tLoss: 0.007766\n",
            "Train Epoch 20 [60/74]\tLoss: 0.003041\n",
            "Train Epoch 20 [70/74]\tLoss: 0.004783\n",
            "[20] Validation Loss: 0.3303, Accuracy: 91.2162%\n",
            "Train Epoch 21 [0/74]\tLoss: 0.002659\n",
            "Train Epoch 21 [10/74]\tLoss: 0.002694\n",
            "Train Epoch 21 [20/74]\tLoss: 0.002751\n",
            "Train Epoch 21 [30/74]\tLoss: 0.002532\n",
            "Train Epoch 21 [40/74]\tLoss: 0.002234\n",
            "Train Epoch 21 [50/74]\tLoss: 0.002860\n",
            "Train Epoch 21 [60/74]\tLoss: 0.003068\n",
            "Train Epoch 21 [70/74]\tLoss: 0.002966\n",
            "[21] Validation Loss: 0.3282, Accuracy: 90.8784%\n",
            "Train Epoch 22 [0/74]\tLoss: 0.002426\n",
            "Train Epoch 22 [10/74]\tLoss: 0.003091\n",
            "Train Epoch 22 [20/74]\tLoss: 0.004010\n",
            "Train Epoch 22 [30/74]\tLoss: 0.001958\n",
            "Train Epoch 22 [40/74]\tLoss: 0.002985\n",
            "Train Epoch 22 [50/74]\tLoss: 0.003510\n",
            "Train Epoch 22 [60/74]\tLoss: 0.002130\n",
            "Train Epoch 22 [70/74]\tLoss: 0.003017\n",
            "[22] Validation Loss: 0.3321, Accuracy: 90.8784%\n",
            "Train Epoch 23 [0/74]\tLoss: 0.002932\n",
            "Train Epoch 23 [10/74]\tLoss: 0.003145\n",
            "Train Epoch 23 [20/74]\tLoss: 0.001909\n",
            "Train Epoch 23 [30/74]\tLoss: 0.003617\n",
            "Train Epoch 23 [40/74]\tLoss: 0.002591\n",
            "Train Epoch 23 [50/74]\tLoss: 0.002154\n",
            "Train Epoch 23 [60/74]\tLoss: 0.002956\n",
            "Train Epoch 23 [70/74]\tLoss: 0.002931\n",
            "[23] Validation Loss: 0.3292, Accuracy: 90.5405%\n",
            "Train Epoch 24 [0/74]\tLoss: 0.002283\n",
            "Train Epoch 24 [10/74]\tLoss: 0.002458\n",
            "Train Epoch 24 [20/74]\tLoss: 0.002237\n",
            "Train Epoch 24 [30/74]\tLoss: 0.002149\n",
            "Train Epoch 24 [40/74]\tLoss: 0.003211\n",
            "Train Epoch 24 [50/74]\tLoss: 0.003111\n",
            "Train Epoch 24 [60/74]\tLoss: 0.002359\n",
            "Train Epoch 24 [70/74]\tLoss: 0.001904\n",
            "[24] Validation Loss: 0.3252, Accuracy: 91.5541%\n",
            "Train Epoch 25 [0/74]\tLoss: 0.002940\n",
            "Train Epoch 25 [10/74]\tLoss: 0.008424\n",
            "Train Epoch 25 [20/74]\tLoss: 0.002701\n",
            "Train Epoch 25 [30/74]\tLoss: 0.001728\n",
            "Train Epoch 25 [40/74]\tLoss: 0.001837\n",
            "Train Epoch 25 [50/74]\tLoss: 0.001980\n",
            "Train Epoch 25 [60/74]\tLoss: 0.002034\n",
            "Train Epoch 25 [70/74]\tLoss: 0.003160\n",
            "[25] Validation Loss: 0.3237, Accuracy: 91.5541%\n",
            "Train Epoch 26 [0/74]\tLoss: 0.001758\n",
            "Train Epoch 26 [10/74]\tLoss: 0.004555\n",
            "Train Epoch 26 [20/74]\tLoss: 0.002409\n",
            "Train Epoch 26 [30/74]\tLoss: 0.002897\n",
            "Train Epoch 26 [40/74]\tLoss: 0.002527\n",
            "Train Epoch 26 [50/74]\tLoss: 0.002285\n",
            "Train Epoch 26 [60/74]\tLoss: 0.001642\n",
            "Train Epoch 26 [70/74]\tLoss: 0.002578\n",
            "[26] Validation Loss: 0.3269, Accuracy: 91.2162%\n",
            "Train Epoch 27 [0/74]\tLoss: 0.001903\n",
            "Train Epoch 27 [10/74]\tLoss: 0.003102\n",
            "Train Epoch 27 [20/74]\tLoss: 0.002118\n",
            "Train Epoch 27 [30/74]\tLoss: 0.001983\n",
            "Train Epoch 27 [40/74]\tLoss: 0.002379\n",
            "Train Epoch 27 [50/74]\tLoss: 0.002229\n",
            "Train Epoch 27 [60/74]\tLoss: 0.002320\n",
            "Train Epoch 27 [70/74]\tLoss: 0.004078\n",
            "[27] Validation Loss: 0.3210, Accuracy: 91.2162%\n",
            "Train Epoch 28 [0/74]\tLoss: 0.001672\n",
            "Train Epoch 28 [10/74]\tLoss: 0.002301\n",
            "Train Epoch 28 [20/74]\tLoss: 0.001697\n",
            "Train Epoch 28 [30/74]\tLoss: 0.006107\n",
            "Train Epoch 28 [40/74]\tLoss: 0.001787\n",
            "Train Epoch 28 [50/74]\tLoss: 0.002164\n",
            "Train Epoch 28 [60/74]\tLoss: 0.002899\n",
            "Train Epoch 28 [70/74]\tLoss: 0.002280\n",
            "[28] Validation Loss: 0.3163, Accuracy: 91.2162%\n",
            "Train Epoch 29 [0/74]\tLoss: 0.001814\n",
            "Train Epoch 29 [10/74]\tLoss: 0.001729\n",
            "Train Epoch 29 [20/74]\tLoss: 0.002022\n",
            "Train Epoch 29 [30/74]\tLoss: 0.002738\n",
            "Train Epoch 29 [40/74]\tLoss: 0.002700\n",
            "Train Epoch 29 [50/74]\tLoss: 0.001738\n",
            "Train Epoch 29 [60/74]\tLoss: 0.001709\n",
            "Train Epoch 29 [70/74]\tLoss: 0.002581\n",
            "[29] Validation Loss: 0.3232, Accuracy: 91.2162%\n",
            "[FINAL] Test Loss 0.3018, Accuracy: 91.9463%\n",
            "Best Accuracy:  91.89189189189189\n",
            "Elasped Time: 0h, 20m, 56s\n",
            "time: 0h, 20m, 56s\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "import wandb\n",
        "wandb.init(project='activelearning1_doyeon')\n",
        "\n",
        "### GPU Setting ###\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(DEVICE)\n",
        "\n",
        "### Custom Dataset ###\n",
        "class CUB2011(Dataset):\n",
        "  def __init__(self, transform, mode='train'):\n",
        "    self.transform = transform\n",
        "    self.mode = mode\n",
        "\n",
        "    if self.mode == 'train':\n",
        "      self.image_folder = os.listdir('./datasets/train')\n",
        "    elif self.mode == 'valid':\n",
        "      self.image_folder = os.listdir('./datasets/valid')\n",
        "    elif self.mode == 'test':\n",
        "      self.image_folder = os.listdir('./datasets/test')\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_folder)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path= self.image_folder[idx]\n",
        "    img = Image.open(os.path.join('./datasets', self.mode, img_path)).convert('RGB')\n",
        "    img = self.transform(img)\n",
        "    label = img_path.split('_')[-1].split('.')[0]\n",
        "    label = int(label)\n",
        "    return (img, label)\n",
        "\n",
        "### Data Preprocessing ###\n",
        "transforms_train = transforms.Compose([transforms.Resize((448, 448)), transforms.ToTensor()])\n",
        "transforms_valtest = transforms.Compose([transforms.Resize((448, 448)), transforms.ToTensor()])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_set = CUB2011(mode='train', transform=transforms_train)\n",
        "val_set = CUB2011(mode= 'valid', transform=transforms_valtest)\n",
        "test_set = CUB2011(mode='test', transform=transforms_valtest)\n",
        "print('Num of each dataset:', len(train_set), len(val_set), len(test_set))\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader (val_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader (test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(\"Loaded dataloader\")\n",
        "\n",
        "### Model / Optimzier ###\n",
        "EPOCH = 30\n",
        "lr = 0.1\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "### Transfer Learning ###\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn. Linear(num_features, 50)\n",
        "model.to(DEVICE)\n",
        "optimizer = optim.SGD (model.parameters(), lr=lr)\n",
        "print(\"Created a learning model and optimizer\")\n",
        "\n",
        "\n",
        "### Train/Evaluation ###\n",
        "def train(model, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  for i, (image, target) in enumerate(train_loader):\n",
        "    image, target = image.to(DEVICE), target.to(DEVICE)\n",
        "    output = model(image)\n",
        "    optimizer.zero_grad()\n",
        "    train_loss = F.cross_entropy(output, target).to(DEVICE)\n",
        "\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "      print(f'Train Epoch {epoch} [{i}/{len(train_loader)}]\\tLoss: {train_loss.item():.6f}')\n",
        "  return train_loss\n",
        "\n",
        "def evaluate(model, val_loader):\n",
        "  model.eval()\n",
        "  eval_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for i, (image, target) in enumerate (val_loader):\n",
        "      image, target = image.to(DEVICE), target.to(DEVICE)\n",
        "      output = model(image)\n",
        "      eval_loss += F.cross_entropy (output, target, reduction='sum').item()\n",
        "      pred = output.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.view_as (pred)).sum().item()\n",
        "    eval_loss /= len(val_loader.dataset)\n",
        "    eval_accuracy = 100 * correct / len(val_loader.dataset)\n",
        "    return eval_loss, eval_accuracy\n",
        "\n",
        "### Main ###\n",
        "start = time.time()\n",
        "best = 0\n",
        "for epoch in range(EPOCH):\n",
        "  train_loss = train(model, train_loader, optimizer, epoch)\n",
        "  val_loss, val_accuracy = evaluate(model, val_loader)\n",
        "\n",
        "  # Logging for model with augmentation\n",
        "  wandb.log({\n",
        "        'lr': lr,\n",
        "        'BATCH_SIZE': BATCH_SIZE,\n",
        "        'train_loss': train_loss.item(),\n",
        "        'val_loss': val_loss,\n",
        "        'val_accuracy': val_accuracy,\n",
        "    })\n",
        "\n",
        "  # Save best model\n",
        "  if val_accuracy > best:\n",
        "    best = val_accuracy\n",
        "    torch.save(model.state_dict(), \"./best_model.pth\")\n",
        "  print(f'[{epoch}] Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}%')\n",
        "\n",
        "# Test result\n",
        "test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "wandb.log({'test_accuracy': test_accuracy})\n",
        "print(f'[FINAL] Test Loss {test_loss:.4f}, Accuracy: {test_accuracy:.4f}%')\n",
        "end = time.time()\n",
        "elasped_time = end - start\n",
        "\n",
        "print(\"Best Accuracy: \", best)\n",
        "print(f\"Elasped Time: {int(elasped_time/3600)}h, {int(elasped_time/60)}m, {int(elasped_time%60)}s\")\n",
        "print(f\"time: {int (elasped_time/3600)}h, {int(elasped_time/60)}m, {int(elasped_time%60)}s\")"
      ]
    }
  ]
}